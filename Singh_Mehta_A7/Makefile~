#Author: Vishal Mehta , Harshali Singh

bucket_name = cs6240-viha

hstart:
	start-dfs.sh
	start-yarn.sh
	mr-jobhistory-daemon.sh start historyserver

hstop:
	mr-jobhistory-daemon.sh stop historyserver
	stop-yarn.sh
	stop-dfs.sh

hduser:
	hadoop fs -mkdir -p /user/hduser
	hadoop fs -mkdir -p /user/hduser/input

hdfs:
	hadoop fs -put all/* /user/hduser/input/

delete:
	hadoop fs -rm -r -f /user/hduser/models
	hadoop fs -rm -r -f /user/hduser/output
	hadoop fs -rm -r -f /user/hduser/intermediate_output
	rm -rf output
	rm -rf out

compile:
	#Predictions
	rm -rf com/mapreduce/prediction/*.class
	javac -cp /home/hduser/Downloads/lib/hadoop-annotations-2.6.3.jar:/home/hduser/Downloads/lib/hadoop-common-2.6.3.jar:/home/hduser/Downloads/lib/hadoop-mapreduce-client-core-2.6.3.jar:/home/hduser/Downloads/lib/commons-cli-1.2.jar:/home/hduser/Downloads/lib/weka-3.7.3.jar com/mapreduce/prediction/*.java
	jar cvf Prediction.jar com/mapreduce/prediction/*.class

pseudo:
	#rm -rf output
	#hadoop fs -rm -r -f /user/hduser/output
	hadoop jar Prediction.jar com.mapreduce.prediction.Prediction input output
	hadoop fs -get output
	cat output/part* > testOutput

jar:
	sbt package
	cp target/scala-*/confusion_*.jar Confusion.jar

run: jar
	rm -rf out
	sbt run
	cat out/part* > matrix

script:
	chmod 777 script.sh
	./script.sh
	
clean:
	rm -rf out derby.log metastore_db project target
	rm -rf *.class
	rm -rf *.jar
	rm -rf *.txt

emr:
	#aws s3 mb s3://${bucket_name}
	aws s3 cp MissedConnection.jar s3://${bucket_name}/job/
	#aws s3 cp all s3://${bucket_name}/input/ --recursive
	aws s3 rm s3://${bucket_name}/output --recursive
	aws emr create-cluster \
	--name "Test Cluster_A5" \
	--release-label emr-4.3.0 \
	--instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=c1.medium \
                      InstanceGroupType=CORE,InstanceCount=2,InstanceType=c1.medium \
	--steps Type=CUSTOM_JAR,Name="Test_A5 JAR Step",ActionOnFailure=CONTINUE,Jar=s3://${bucket_name}/job/MissedConnection.jar,MainClass=missed.MissedConnection,Args=[s3://${bucket_name}/input,s3://${bucket_name}/output] \
	--auto-terminate \
	--log-uri s3://${bucket_name}/logs \
	--service-role EMR_DefaultRole \
	--ec2-attributes InstanceProfile=EMR_EC2_DefaultRole,AvailabilityZone=us-west-2a \
	--enable-debugging > Clusterid.txt

output:
	#Check the status of the cluster
	python test.py
	# get the output
	aws s3 sync s3://${bucket_name}/output output 
	cat output/part* > finalOutput
	#rm -rf *.txt

run: emr output

report:
	Rscript -e "rmarkdown::render('Report_A5.Rmd')"

weka:
	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:`echo /home/hduser/Downloads/weka/*.jar | sed 's/ /:/g'`
